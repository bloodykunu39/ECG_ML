{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py #type: ignore\n",
    "import pandas as pd #type: ignore\n",
    "import numpy as np #type:ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the CSV file:\n",
      "   exam_id  age  is_male  nn_predicted_age  1dAVb   RBBB   LBBB     SB     ST  \\\n",
      "0  1169160   38     True         40.160484  False  False  False  False  False   \n",
      "1  2873686   73     True         67.059440  False  False  False  False  False   \n",
      "2   168405   67     True         79.621740  False  False  False  False  False   \n",
      "3   271011   41     True         69.750260  False  False  False  False  False   \n",
      "4   384368   73     True         78.873460  False  False  False  False  False   \n",
      "\n",
      "      AF  patient_id  death     timey  normal_ecg         trace_file  \n",
      "0  False      523632  False  2.098628        True  exams_part13.hdf5  \n",
      "1  False     1724173  False  6.657529       False  exams_part13.hdf5  \n",
      "2   True       51421  False  4.282188       False  exams_part13.hdf5  \n",
      "3  False     1737282  False  4.038353        True  exams_part13.hdf5  \n",
      "4  False      331652  False  3.786298       False  exams_part13.hdf5  \n"
     ]
    }
   ],
   "source": [
    "path = '/zenodo_data/exams_extracted/'\n",
    "\n",
    "# path = '/home/pingal/Documents/ECG_data/'\n",
    "filename = path + 'exams.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "print(\"First few rows of the CSV file:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exam ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_1dAVb = []\n",
    "code_RBBB = []\n",
    "code_LBBB = []\n",
    "code_SB = []\n",
    "code_ST = []\n",
    "code_AF = []\n",
    "code_normal = []\n",
    "for index in range(df.shape[0]):\n",
    "    if df['1dAVb'][index] == True:\n",
    "        code_1dAVb.append(df['exam_id'][index])\n",
    "    if df['RBBB'][index] == True:\n",
    "        code_RBBB.append(df['exam_id'][index])\n",
    "    if df['LBBB'][index] == True:\n",
    "        code_LBBB.append(df['exam_id'][index])\n",
    "    if df['SB'][index] == True:\n",
    "        code_SB.append(df['exam_id'][index])\n",
    "    if df['ST'][index] == True:\n",
    "        code_ST.append(df['exam_id'][index])\n",
    "    if df['AF'][index] == True:\n",
    "        code_AF.append(df['exam_id'][index])\n",
    "    if df['normal_ecg'][index] == True:\n",
    "        code_normal.append(df['exam_id'][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of data with 1dAVb: 5716\n",
      "Lenght of data with RBBB: 9672\n",
      "Lenght of data with LBBB: 6026\n",
      "Lenght of data with SB: 5605\n",
      "Lenght of data with ST: 7584\n",
      "Lenght of data with AF: 7033\n",
      "Lenght of data with normal ecg: 134657\n"
     ]
    }
   ],
   "source": [
    "print(f'Lenght of data with 1dAVb: {len(code_1dAVb)}')\n",
    "print(f'Lenght of data with RBBB: {len(code_RBBB)}')\n",
    "print(f'Lenght of data with LBBB: {len(code_LBBB)}')\n",
    "print(f'Lenght of data with SB: {len(code_SB)}')\n",
    "print(f'Lenght of data with ST: {len(code_ST)}')\n",
    "print(f'Lenght of data with AF: {len(code_AF)}')\n",
    "print(f'Lenght of data with normal ecg: {len(code_normal)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = ['1dAVB', 'RBBB', 'LBBB', 'SB', 'ST', 'AF', 'normal_ecg']\n",
    "size = [len(code_1dAVb), len(code_RBBB), len(code_RBBB), len(code_SB), len(code_ST), len(code_AF), len(code_normal)]\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    'diseases' : diseases,\n",
    "    'size': size}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diseases</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1dAVB</td>\n",
       "      <td>5716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBBB</td>\n",
       "      <td>9672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LBBB</td>\n",
       "      <td>9672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SB</td>\n",
       "      <td>5605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST</td>\n",
       "      <td>7584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AF</td>\n",
       "      <td>7033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>normal_ecg</td>\n",
       "      <td>134657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     diseases    size\n",
       "0       1dAVB    5716\n",
       "1        RBBB    9672\n",
       "2        LBBB    9672\n",
       "3          SB    5605\n",
       "4          ST    7584\n",
       "5          AF    7033\n",
       "6  normal_ecg  134657"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disease Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/pingal/Documents/ECG_data/'\n",
    "path = '/zenodo_data/exams_extracted/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1dAVb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_1dAVb:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_1dAVB', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LBBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_LBBB:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_LBBB', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RBBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_RBBB:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_RBBB', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_SB:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_SB', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_ST:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_ST', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_AF:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_AF', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### normal_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_normal:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_normal', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Superposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1dAVB = np.load('data_1dAVB.npy')\n",
    "data_RBBB = np.load('data_RBBB.npy')\n",
    "data_LBBB = np.load('data_LBBB.npy')\n",
    "data_SB = np.load('data_SB.npy')\n",
    "data_ST = np.load('data_ST.npy')\n",
    "data_AF = np.load('data_AF.npy')\n",
    "data_normal = np.load('data_normal.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6873, 4096, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_AF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choice(arr):\n",
    "    selected_indices = np.random.choice(arr.shape[0], size=5000, replace=False)\n",
    "    selected_elements = arr[selected_indices, :, :]\n",
    "    return selected_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4096, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_choice(data_1dAVB).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chdir to MAIN\n",
    "defalut_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_choice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msmoothening\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coarsegrain\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n\u001b[1;32m----> 5\u001b[0m data\u001b[38;5;241m=\u001b[39m \u001b[43mrandom_choice\u001b[49m(data_1dAVB)\n\u001b[0;32m      6\u001b[0m split_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;241m%\u001b[39msplit_number \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random_choice' is not defined"
     ]
    }
   ],
   "source": [
    "from encoding import superposition\n",
    "from time import time\n",
    "from smoothening import coarsegrain\n",
    "from joblib import Parallel, delayed\n",
    "data= random_choice(data_1dAVB[0:5000,:,:])\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    for j in cc:\n",
    "        sup=superposition(j)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/1dAVB_svd_zenedo_raw' + '_'+str(i) + '.npy',sup)\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_1dAVB_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data_rbb\n",
    "data= random_choice(data_RBBB[:5000,:,:])\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    for j in cc:\n",
    "        sup=superposition(j)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/RBBB_svd_zenedo_raw' + '_'+str(i) + '.npy',sup)\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_RBBB_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= random_choice(data_LBBB[:5000,:,:])\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    for j in cc:\n",
    "        sup=superposition(j)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/LBBB_svd_zenedo_raw' + '_'+str(i) + '.npy',sup)\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_LBBB_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= random_choice(data_SB[:5000,:,:])\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    for j in cc:\n",
    "        sup=superposition(j)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/SB_svd_zenedo_raw' + '_'+str(i) + '.npy',sup)\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_SB_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= random_choice(data_ST[:5000,:,:])\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    for j in cc:\n",
    "        sup=superposition(j)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/ST_svd_zenedo_raw' + '_'+str(i) + '.npy',sup)\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_ST_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= random_choice(data_AF[:5000,:,:])\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    for j in cc:\n",
    "        sup=superposition(j)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/AF_svd_zenedo_raw' + '_'+str(i) + '.npy',sup)\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_AF_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= random_choice(data_normal[:5000,:,:])\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    for j in cc:\n",
    "        sup=superposition(j)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/normal_svd_zenedo_raw' + '_'+str(i) + '.npy',sup)\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_normal_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
