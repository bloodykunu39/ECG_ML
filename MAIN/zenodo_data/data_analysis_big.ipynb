{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py #type: ignore\n",
    "import pandas as pd #type: ignore\n",
    "import numpy as np #type:ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/zenodo_data/exams_extracted/'\n",
    "\n",
    "# path = '/home/pingal/Documents/ECG_data/'\n",
    "filename = path + 'exams.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "print(\"First few rows of the CSV file:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exam ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_1dAVb = []\n",
    "code_RBBB = []\n",
    "code_LBBB = []\n",
    "code_SB = []\n",
    "code_ST = []\n",
    "code_AF = []\n",
    "code_normal = []\n",
    "for index in range(df.shape[0]):\n",
    "    if df['1dAVb'][index] == True:\n",
    "        code_1dAVb.append(df['exam_id'][index])\n",
    "    if df['RBBB'][index] == True:\n",
    "        code_RBBB.append(df['exam_id'][index])\n",
    "    if df['LBBB'][index] == True:\n",
    "        code_LBBB.append(df['exam_id'][index])\n",
    "    if df['SB'][index] == True:\n",
    "        code_SB.append(df['exam_id'][index])\n",
    "    if df['ST'][index] == True:\n",
    "        code_ST.append(df['exam_id'][index])\n",
    "    if df['AF'][index] == True:\n",
    "        code_AF.append(df['exam_id'][index])\n",
    "    if df['normal_ecg'][index] == True:\n",
    "        code_normal.append(df['exam_id'][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Lenght of data with 1dAVb: {len(code_1dAVb)}')\n",
    "print(f'Lenght of data with RBBB: {len(code_RBBB)}')\n",
    "print(f'Lenght of data with LBBB: {len(code_LBBB)}')\n",
    "print(f'Lenght of data with SB: {len(code_SB)}')\n",
    "print(f'Lenght of data with ST: {len(code_ST)}')\n",
    "print(f'Lenght of data with AF: {len(code_AF)}')\n",
    "print(f'Lenght of data with normal ecg: {len(code_normal)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = ['1dAVB', 'RBBB', 'LBBB', 'SB', 'ST', 'AF', 'normal_ecg']\n",
    "size = [len(code_1dAVb), len(code_RBBB), len(code_RBBB), len(code_SB), len(code_ST), len(code_AF), len(code_normal)]\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    'diseases' : diseases,\n",
    "    'size': size}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disease Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/pingal/Documents/ECG_data/'\n",
    "path = '/zenodo_data/exams_extracted/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1dAVb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_1dAVb:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_1dAVB', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LBBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_LBBB:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_LBBB', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RBBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_RBBB:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_RBBB', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_SB:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_SB', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_ST:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_ST', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_AF:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_AF', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### normal_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "\n",
    "for index in range(0,17):\n",
    "    filename = 'exams_part' + str(index) + '.hdf5'\n",
    "\n",
    "    data = h5py.File(path+filename)\n",
    "    data_tracings = data['tracings']\n",
    "    data_id = data['exam_id']\n",
    "\n",
    "    for elem in range(data_tracings.shape[0]):\n",
    "        if data_id[elem] in code_normal:\n",
    "            counter.append(data_tracings[elem])\n",
    "\n",
    "\n",
    "np.save('data_normal', counter)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Superposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1dAVB = np.load('data_1dAVB.npy')\n",
    "data_RBBB = np.load('data_RBBB.npy')\n",
    "data_LBBB = np.load('data_LBBB.npy')\n",
    "data_SB = np.load('data_SB.npy')\n",
    "data_ST = np.load('data_ST.npy')\n",
    "data_AF = np.load('data_AF.npy')\n",
    "data_normal = np.load('data_normal.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choice(arr):\n",
    "    selected_indices = np.random.choice(arr.shape[0], size=5000, replace=False)\n",
    "    selected_elements = arr[selected_indices, :, :]\n",
    "    return selected_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chdir to MAIN\n",
    "defalut_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoding import superposition\n",
    "from time import time\n",
    "from smoothening import coarsegrain\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data= random_choice(data_1dAVB)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    k=0\n",
    "    for j in cc:\n",
    "        sup=superposition(j,4096)\n",
    "        result.append(coarsegrain(sup,16))\n",
    "       \n",
    "        np.save('zenodo_data/raw/1dAVB_svd_zenedo_raw' + '_'+str(k+i*500) + '.npy',sup)\n",
    "        k+=1\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_1dAVB_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data_rbb\n",
    "data= random_choice(data_RBBB)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    k=0\n",
    "    for j in cc:\n",
    "        sup=superposition(j,4096)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/RBBB_svd_zenedo_raw' + '_'+str(i*500+k) + '.npy',sup)\n",
    "        k+=1\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_RBBB_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= random_choice(data_LBBB)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    k=0\n",
    "    for j in cc:\n",
    "        sup=superposition(j,4096)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/LBBB_svd_zenedo_raw' + '_'+str(i*500+k) + '.npy',sup)\n",
    "        k+=1\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_LBBB_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= random_choice(data_SB)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "    k=0\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    for j in cc:\n",
    "        sup=superposition(j,4096)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/SB_svd_zenedo_raw' + '_'+str(500*i+1) + '.npy',sup)\n",
    "        k+=1\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_SB_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= random_choice(data_ST)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "    k=0\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    for j in cc:\n",
    "        sup=superposition(j,4096)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/ST_svd_zenedo_raw' + '_'+str(i*500+k) + '.npy',sup)\n",
    "        k+=1\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_ST_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= random_choice(data_AF)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "    k=0\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    for j in cc:\n",
    "        sup=superposition(j,4096)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/AF_svd_zenedo_raw' + '_'+str(500*i+k) + '.npy',sup)\n",
    "        k+=1\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_AF_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= random_choice(data_normal)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result=[]\n",
    "    k=0\n",
    "    for j in cc:\n",
    "        sup=superposition(j,4096)\n",
    "        result.append(coarsegrain(sup))\n",
    "        np.save('zenodo_data/raw/normal_svd_zenedo_raw' + '_'+str(i*500+k) + '.npy',sup)\n",
    "        k+=1\n",
    "    result = np.array(result)\n",
    "    cc = []\n",
    "    for j in range(result.shape[0]):\n",
    "        cc.append(result[j].ravel())\n",
    "    # save as txt file\n",
    "    np.savetxt('zenodo_data/cg_16/disease_normal_svd_zenedo_cg_16' + '_'+str(i) + '.txt',cc)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choice(arr):\n",
    "    selected_indices = np.random.choice(arr.shape[0], size=5000, replace=False)\n",
    "    selected_elements = arr[selected_indices, :, :]\n",
    "    return selected_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_1dAVB = np.load('data_1dAVB.npy')\n",
    "# data_RBBB = np.load('data_RBBB.npy')\n",
    "# data_LBBB = np.load('data_LBBB.npy')\n",
    "# data_SB = np.load('data_SB.npy')\n",
    "# data_ST = np.load('data_ST.npy')\n",
    "# data_AF = np.load('data_AF.npy')\n",
    "# data_normal = np.load('data_normal.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "\n",
    "defalut_path = os.getcwd()\n",
    "\n",
    "from time import time\n",
    "from smoothening import coarsegrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def image_matrix(data):\n",
    "    plt.plot(data)\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format = 'png')\n",
    "    plt.close()\n",
    "\n",
    "    buf.seek(0)\n",
    "    image = Image.open(buf)\n",
    "    image_array = np.array(image)\n",
    "    image_mat = image_array.mean(axis = -1)\n",
    "\n",
    "    return image_mat\n",
    "\n",
    "def image_stack_matrix(data):\n",
    "    data_stack = np.zeros(4096, dtype=float)\n",
    "    for iter in range(data.shape[1]):\n",
    "        data_stack += data[:,iter]\n",
    "    image_stack = image_matrix(data_stack)\n",
    "    return image_stack, data_stack\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\LARGE_CNN\\ECG_ML\\MAIN\\zenodo_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 480, 640)\n",
      "Time taken for 0th iteration is 15.198863744735718\n",
      "(50, 480, 640)\n",
      "Time taken for 1th iteration is 16.244571447372437\n",
      "(50, 480, 640)\n",
      "Time taken for 2th iteration is 14.820995807647705\n",
      "(50, 480, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     cc_arr\u001b[38;5;241m.\u001b[39mappend(result_arr[j]\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# save as txt file\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_stack_image/disease_1dAVB_svd_zenedo_im\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,cc_mat)\n\u001b[0;32m     34\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_stack_signal/disease_1dAVB_svd_zenedo_si\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,cc_arr)\n\u001b[0;32m     35\u001b[0m end\u001b[38;5;241m=\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\Guest1\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:1628\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1624\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1625\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch between array dtype (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1626\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat specifier (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1627\u001b[0m                             \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mstr\u001b[39m(X\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;28mformat\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m-> 1628\u001b[0m         fh\u001b[38;5;241m.\u001b[39mwrite(v)\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(footer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1631\u001b[0m     footer \u001b[38;5;241m=\u001b[39m footer\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m comments)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_1dAVB = np.load('data_1dAVB.npy')\n",
    "data= random_choice(data_1dAVB)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result_mat=[]\n",
    "    result_arr = []\n",
    "    for j in cc:\n",
    "        sup=image_stack_matrix(j)\n",
    "        result_mat.append(sup[0])\n",
    "        result_arr.append(sup[1])\n",
    "       \n",
    "    result_mat = np.array(result_mat)\n",
    "    result_arr = np.array(result_arr)\n",
    "\n",
    "    cc_mat = []\n",
    "    cc_arr = []\n",
    "    for j in range(result_mat.shape[0]):\n",
    "        cc_mat.append(result_mat[j].ravel())\n",
    "        cc_arr.append(result_arr[j].ravel())\n",
    "\n",
    "    # save as txt file\n",
    "    np.savetxt('data_stack_image/disease_1dAVB_svd_zenedo_im' + '_'+str(i) + '.txt',cc_mat)\n",
    "    np.savetxt('data_stack_signal/disease_1dAVB_svd_zenedo_si' + '_'+str(i) + '.txt',cc_arr)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "\n",
    "del data_1dAVB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LBBB = np.load('data_LBBB.npy')\n",
    "data= random_choice(data_LBBB)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result_mat=[]\n",
    "    result_arr = []\n",
    "    for j in cc:\n",
    "        sup=image_stack_matrix(j)\n",
    "        result_mat.append(sup[0])\n",
    "        result_arr.append(sup[1])\n",
    "       \n",
    "    result_mat = np.array(result_mat)\n",
    "    result_arr = np.array(result_arr)\n",
    "\n",
    "    cc_mat = []\n",
    "    cc_arr = []\n",
    "    for j in range(result_mat.shape[0]):\n",
    "        cc_mat.append(result_mat[j].ravel())\n",
    "        cc_arr.append(result_arr[j].ravel())\n",
    "\n",
    "    # save as txt file\n",
    "    np.savetxt('data_stack_image/disease_LBBB_svd_zenedo_im' + '_'+str(i) + '.txt',cc_mat)\n",
    "    np.savetxt('data_stack_signal/disease_LBBB_svd_zenedo_si' + '_'+str(i) + '.txt',cc_arr)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "\n",
    "del data_LBBB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_RBBB = np.load('data_RBBB.npy')\n",
    "data= random_choice(data_RBBB)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result_mat=[]\n",
    "    result_arr = []\n",
    "    for j in cc:\n",
    "        sup=image_stack_matrix(j)\n",
    "        result_mat.append(sup[0])\n",
    "        result_arr.append(sup[1])\n",
    "       \n",
    "    result_mat = np.array(result_mat)\n",
    "    result_arr = np.array(result_arr)\n",
    "\n",
    "    cc_mat = []\n",
    "    cc_arr = []\n",
    "    for j in range(result_mat.shape[0]):\n",
    "        cc_mat.append(result_mat[j].ravel())\n",
    "        cc_arr.append(result_arr[j].ravel())\n",
    "\n",
    "    # save as txt file\n",
    "    np.savetxt('data_stack_image/disease_RBBB_svd_zenedo_im' + '_'+str(i) + '.txt',cc_mat)\n",
    "    np.savetxt('data_stack_signal/disease_RBBB_svd_zenedo_si' + '_'+str(i) + '.txt',cc_arr)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "\n",
    "del data_RBBB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_SB = np.load('data_SB.npy')\n",
    "data= random_choice(data_SB)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result_mat=[]\n",
    "    result_arr = []\n",
    "    for j in cc:\n",
    "        sup=image_stack_matrix(j)\n",
    "        result_mat.append(sup[0])\n",
    "        result_arr.append(sup[1])\n",
    "       \n",
    "    result_mat = np.array(result_mat)\n",
    "    result_arr = np.array(result_arr)\n",
    "\n",
    "    cc_mat = []\n",
    "    cc_arr = []\n",
    "    for j in range(result_mat.shape[0]):\n",
    "        cc_mat.append(result_mat[j].ravel())\n",
    "        cc_arr.append(result_arr[j].ravel())\n",
    "\n",
    "    # save as txt file\n",
    "    np.savetxt('data_stack_image/disease_SB_svd_zenedo_im' + '_'+str(i) + '.txt',cc_mat)\n",
    "    np.savetxt('data_stack_signal/disease_SB_svd_zenedo_si' + '_'+str(i) + '.txt',cc_arr)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "\n",
    "del data_SB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ST = np.load('data_ST.npy')\n",
    "data= random_choice(data_ST)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result_mat=[]\n",
    "    result_arr = []\n",
    "    for j in cc:\n",
    "        sup=image_stack_matrix(j)\n",
    "        result_mat.append(sup[0])\n",
    "        result_arr.append(sup[1])\n",
    "       \n",
    "    result_mat = np.array(result_mat)\n",
    "    result_arr = np.array(result_arr)\n",
    "\n",
    "    cc_mat = []\n",
    "    cc_arr = []\n",
    "    for j in range(result_mat.shape[0]):\n",
    "        cc_mat.append(result_mat[j].ravel())\n",
    "        cc_arr.append(result_arr[j].ravel())\n",
    "\n",
    "    # save as txt file\n",
    "    np.savetxt('data_stack_image/disease_ST_svd_zenedo_im' + '_'+str(i) + '.txt',cc_mat)\n",
    "    np.savetxt('data_stack_signal/disease_ST_svd_zenedo_si' + '_'+str(i) + '.txt',cc_arr)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "\n",
    "del data_ST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_AF = np.load('data_AF.npy')\n",
    "data= random_choice(data_AF)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result_mat=[]\n",
    "    result_arr = []\n",
    "    for j in cc:\n",
    "        sup=image_stack_matrix(j)\n",
    "        result_mat.append(sup[0])\n",
    "        result_arr.append(sup[1])\n",
    "       \n",
    "    result_mat = np.array(result_mat)\n",
    "    result_arr = np.array(result_arr)\n",
    "\n",
    "    cc_mat = []\n",
    "    cc_arr = []\n",
    "    for j in range(result_mat.shape[0]):\n",
    "        cc_mat.append(result_mat[j].ravel())\n",
    "        cc_arr.append(result_arr[j].ravel())\n",
    "\n",
    "    # save as txt file\n",
    "    np.savetxt('data_stack_image/disease_AF_svd_zenedo_im' + '_'+str(i) + '.txt',cc_mat)\n",
    "    np.savetxt('data_stack_signal/disease_AF_svd_zenedo_si' + '_'+str(i) + '.txt',cc_arr)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "\n",
    "del data_AF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal = np.load('data_normal.npy')\n",
    "data= random_choice(data_normal)\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    start = time()\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    start = time()\n",
    "    result_mat=[]\n",
    "    result_arr = []\n",
    "    for j in cc:\n",
    "        sup=image_stack_matrix(j)\n",
    "        result_mat.append(sup[0])\n",
    "        result_arr.append(sup[1])\n",
    "       \n",
    "    result_mat = np.array(result_mat)\n",
    "    result_arr = np.array(result_arr)\n",
    "\n",
    "    cc_mat = []\n",
    "    cc_arr = []\n",
    "    for j in range(result_mat.shape[0]):\n",
    "        cc_mat.append(result_mat[j].ravel())\n",
    "        cc_arr.append(result_arr[j].ravel())\n",
    "\n",
    "    # save as txt file\n",
    "    np.savetxt('data_stack_image/disease_normal_svd_zenedo_im' + '_'+str(i) + '.txt',cc_mat)\n",
    "    np.savetxt('data_stack_signal/disease_normal_svd_zenedo_si' + '_'+str(i) + '.txt',cc_arr)\n",
    "    end=time()\n",
    "    print(f'Time taken for {i}th iteration is {end-start}')\n",
    "\n",
    "del data_SB\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
